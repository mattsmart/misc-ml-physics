{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "665bd57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "import os, torch, time, math, sys, re, csv\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from pathlib import Path, PurePath\n",
    "from zipfile import ZipFile\n",
    "import urllib.request\n",
    "import shutil\n",
    "import requests, zipfile, io\n",
    "\n",
    "sys.path.append('..' + os.sep )\n",
    "from src import default\n",
    "from src.data import download as dl, tokenization as tkn, custom_dataset as cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bc3b605a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseDataset(Dataset):\n",
    "    \"\"\"You can choose to set a transform (generally a tokenizer) to transform\n",
    "    what is returned into another form of data more suitable (generally a \n",
    "    tensor of tokens).\n",
    "\n",
    "    To change what a sample is, need only change the method :\n",
    "        get_instance_pretransform\n",
    "    \"\"\"\n",
    "    def __init__(self, transform=None):\n",
    "        self.data = [1,2,3]\n",
    "        self.transform = transform\n",
    "        \n",
    "        if self.transform is None:\n",
    "            self.get_instance = self.get_instance_raw\n",
    "        else:\n",
    "            self.get_instance = self.get_instance_transformed # how to get a sample\n",
    "                                                        # from the dataset\n",
    "        return\n",
    "    \n",
    "    def __len__(self):\n",
    "        # gives number of samples in dataset\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # uses function as defined by self.get_instance\n",
    "        return self.get_instance(idx)\n",
    "    \n",
    "    def set_transform(self, transform):\n",
    "        # can set transform and will change how we get an instance\n",
    "        self.transform = transform # transform.encode could be used with rawTokenizer (instead of FastTokenizer)\n",
    "        self.get_instance = self.get_instance_transformed\n",
    "    \n",
    "    def get_instance_raw(self, idx):\n",
    "        return self.data[idx]\n",
    "    \n",
    "    def get_instance_transformed(self, idx):\n",
    "        \"\"\"\n",
    "        Once tranform is defined, can get item already transformed\n",
    "\n",
    "        Input\n",
    "            idx (int) : index of sample to fetch and transform\n",
    "        Return\n",
    "            transformed sample\n",
    "        \"\"\"\n",
    "        instance = self.get_instance_raw(idx)\n",
    "        # tokenize on-the-fly\n",
    "        instance = self.transform( instance, return_tensors='pt')\n",
    "        return instance['input_ids'][0]\n",
    "    \n",
    "\n",
    "class ArxivDataset(BaseDataset):\n",
    "    \"\"\"\n",
    "    This Dataset takes the Arxiv data downloaded into a '.csv' files and, when\n",
    "    called, returns a sample from a list of samples with data_field.\n",
    "    \"\"\"\n",
    "    def __init__(self, csvfile, transform=None, data_field='summary'):\n",
    "        \"\"\"\n",
    "        Loads all of the data and cleans it up slightly. Might wants to call it\n",
    "        something else instead of 'raw', but for now will do. Sets a transform\n",
    "        of the data (which is how data is presented if fetched).\n",
    "\n",
    "        Input\n",
    "            csvfile (str)               : csv file containing data\n",
    "            data_field (str)            : name of the field to be used in train on\n",
    "            transform (function, opt)   : a transform of the data if one already\n",
    "                                            exists\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.data = pd.read_csv(csvfile)\n",
    "        self.data_field = data_field\n",
    "        # last one r'\\s+|\\\\n' seems to be the only one that works\n",
    "        remove_lst = ['\\r\\n','\\n','\\ n',r'\\\\n',r'\\n',r'\\s+|\\\\n']\n",
    "        self.data.replace(remove_lst,' ',regex=True, inplace=True)\n",
    "\n",
    "    def get_instance_raw(self, idx):\n",
    "        # returns some form of the text which will be our sample\n",
    "        return self.data[self.data_field][idx]\n",
    "\n",
    "class WikiTextDataset(BaseDataset):\n",
    "    def __init__(self, dataname='wikitext-2-raw', bptt=35):\n",
    "        assert dataname in ['wikitext-2','wikitext-2-raw','wikitext-103','wikitext-103-raw']\n",
    "        assert isinstance(bptt,int)\n",
    "        super().__init__()\n",
    "        self.dirname = dataname\n",
    "        self.bptt = bptt\n",
    "        zipfile = f'{self.dirname}-v1.zip'\n",
    "        url = f'https://s3.amazonaws.com/research.metamind.io/wikitext/{zipfile}'\n",
    "        \n",
    "        if not Path(default.RAW_DATA_DIR,self.dirname).exists():\n",
    "            r = requests.get(url)\n",
    "            z = ZipFile(io.BytesIO(r.content))\n",
    "            z.extractall(default.RAW_DATA_DIR)\n",
    "        \n",
    "        split = ['wiki.train','wiki.valid','wiki.test']      \n",
    "        if 'raw' in self.dirname:\n",
    "            split = [ s+'.raw' for s in split ]\n",
    "        else:\n",
    "            split = [ s+'.raw' for s in split ]\n",
    "\n",
    "        for file in split:\n",
    "            dataString = ''\n",
    "            with open(PurePath(default.RAW_DATA_DIR,self.dirname,file), 'r') as f:\n",
    "                dataString += ' '.join([line.strip() for line in f])\n",
    "                #dataString += ' '.join([line for line in f])\n",
    "            #dataString = \"\".join([s for s in dataString.splitlines(True) if s.strip(\"\\r\\n\")])\n",
    "        wordList = dataString.split(' ')\n",
    "        self.data = [' '.join(wordList[i:i + bptt]) for i in range(0, len(wordList), bptt)]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fb45e1ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Using arxiv_10000.csv for training <<\n"
     ]
    }
   ],
   "source": [
    "# download data\n",
    "nbrResults = 10**4 # number of data samples to download\n",
    "filename = f'arxiv_{nbrResults}'\n",
    "extension = '.csv'\n",
    "filename += extension\n",
    "\n",
    "filepath = default.RAW_DATA_DIR + os.sep + filename\n",
    "\n",
    "if not os.path.exists(filepath):\n",
    "    dl.arxiv_api( default.RAW_DATA_DIR, filename, max_results=nbrResults ) # TODO : CHANGE SO THAT NOT CONSTANTLY LOADING DATA\n",
    "print(f'>> Using {filename} for training <<')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4f42672f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ArxivDataset(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "afa9cc86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The effect of the electron-electron cusp on the convergence of configuration interaction (CI) wave functions is examined. By analogy with the pseudopotential approach for electron-ion interactions, an effective electron-electron interaction is developed which closely reproduces the scattering of the Coulomb interaction but is smooth and finite at zero electron-electron separation. The exact many-electron wave function for this smooth effective interaction has o cusp at zero electron-electron separation. We perform CI and quantum Monte Carlo calculations for He and Be atoms, both with the Coulomb electron-electron interaction and with the smooth effective electron-electron interaction. We find that convergence of the CI expansion of the wave function for the smooth electron-electron interaction is ot significantly improved compared with that for the divergent Coulomb interaction for energy differences on the order of 1 mHartree. This shows that, contrary to popular belief, description of the electron-electron cusp is ot a limiting factor, to within chemical accuracy, for CI calculations.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f191db10",
   "metadata": {},
   "outputs": [],
   "source": [
    "tknzerType = 'BPE'\n",
    "tknzrFile = default.TOK_DIR + os.sep + filename + '_' + tknzerType + '.json'\n",
    "\n",
    "# load PreTrainedTokenizerFast, for __call__. __call__ not implemented in\n",
    "# the base Tokenizer class... that sounds silly, but it is what it is\n",
    "tknzr = tkn.load_tokenizer(tknzrFile, **default.special_token_lst)\n",
    "\n",
    "# set tknzr as the transform\n",
    "dataset.set_transform( tknzr )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "317bb9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "wt = WikiTextDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c79923c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'actors Mark Strong and Derek Jacobi . He was cast in the 2005 theatre productions of the Philip Ridley play Mercury Fur , which was performed at the Drum Theatre in Plymouth and the Menier'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wt[3]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

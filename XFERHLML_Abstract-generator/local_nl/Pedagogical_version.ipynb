{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CkZBan6-z_ZI"
   },
   "source": [
    "## First step : \n",
    "### extracting the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hXpbde5k_ONh",
    "outputId": "337f1266-bf3f-4146-adf8-61966c083ba3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting feedparser\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/b2/15bf6781a861bbc5dd801d467f26448fb322bfedcd30f2e62b148d104dfb/feedparser-6.0.8-py3-none-any.whl (81kB)\n",
      "\r",
      "\u001b[K     |████                            | 10kB 16.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████                        | 20kB 20.1MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▏                   | 30kB 16.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▏               | 40kB 15.0MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▏           | 51kB 7.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▎       | 61kB 8.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▎   | 71kB 8.0MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 81kB 5.3MB/s \n",
      "\u001b[?25hCollecting sgmllib3k\n",
      "  Downloading https://files.pythonhosted.org/packages/9e/bd/3704a8c3e0942d711c1299ebf7b9091930adae6675d7c8f476a7ce48653c/sgmllib3k-1.0.0.tar.gz\n",
      "Building wheels for collected packages: sgmllib3k\n",
      "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-cp37-none-any.whl size=6067 sha256=c65991c7e3607fb8bc69d7049e0fc1a1ea63bffacd21764e1a4e05b347ef89db\n",
      "  Stored in directory: /root/.cache/pip/wheels/f1/80/5a/444ba08a550cdd241bd9baf8bae44be750efe370adb944506a\n",
      "Successfully built sgmllib3k\n",
      "Installing collected packages: sgmllib3k, feedparser\n",
      "Successfully installed feedparser-6.0.8 sgmllib3k-1.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install feedparser\n",
    "\n",
    "import urllib.request\n",
    "import feedparser\n",
    "\n",
    "# Base api query url\n",
    "base_url = 'http://export.arxiv.org/api/query?';\n",
    "\n",
    "# Search parameters\n",
    "search_query = 'all:electron' # search for electron in all fields\n",
    "start = 0                     # retreive the first 5 results\n",
    "max_results = 10**4\n",
    "\n",
    "query = 'search_query=%s&start=%i&max_results=%i' % (search_query,\n",
    "                                                     start,\n",
    "                                                     max_results)\n",
    "\n",
    "# perform a GET request using the base_url and query\n",
    "response = urllib.request.urlopen(base_url+query).read()\n",
    "\n",
    "# parse the response using feedparser\n",
    "feed = feedparser.parse(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SCygoWCJ0VP8"
   },
   "source": [
    "### convert it into a list + dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "qZj127blp3uA"
   },
   "outputs": [],
   "source": [
    "#coloums of interasts (maybe?)\n",
    "col=['title', 'summary', 'authors', 'arxiv_primary_category', 'tags']\n",
    "\n",
    "# Run through each entry, and fill the information into a list\n",
    "data_list=[]\n",
    "for c in col:\n",
    "  abstract_list=[]\n",
    "  for entry in feed.entries:\n",
    "    abstract_list.append(entry.get(c))\n",
    "  data_list.append(abstract_list)\n",
    "\n",
    "# convert into a panda dataframe (maybe more visible + have some pros I might need)\n",
    "import pandas as pd\n",
    "data_df = pd.DataFrame(data_list,index=col)\n",
    "data_df=data_df.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "VU5l6yin0uJU"
   },
   "outputs": [],
   "source": [
    "data_df.to_csv('arXiv10.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 588
    },
    "id": "2cihhiBucihA",
    "outputId": "bf0893d4-dd7d-4567-8afd-bf7c38656ba1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "      <th>authors</th>\n",
       "      <th>arxiv_primary_category</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Impact of Electron-Electron Cusp on Configurat...</td>\n",
       "      <td>The effect of the electron-electron cusp on th...</td>\n",
       "      <td>[{'name': 'David Prendergast'}, {'name': 'M. N...</td>\n",
       "      <td>{'term': 'cond-mat.str-el', 'scheme': 'http://...</td>\n",
       "      <td>[{'term': 'cond-mat.str-el', 'scheme': 'http:/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Electron thermal conductivity owing to collisi...</td>\n",
       "      <td>We calculate the thermal conductivity of elect...</td>\n",
       "      <td>[{'name': 'P. S. Shternin'}, {'name': 'D. G. Y...</td>\n",
       "      <td>{'term': 'astro-ph', 'scheme': 'http://arxiv.o...</td>\n",
       "      <td>[{'term': 'astro-ph', 'scheme': 'http://arxiv....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Electron pairing: from metastable electron pai...</td>\n",
       "      <td>Starting from the shell structure in atoms and...</td>\n",
       "      <td>[{'name': 'Guo-Qiang Hai'}, {'name': 'Ladir Câ...</td>\n",
       "      <td>{'term': 'cond-mat.str-el', 'scheme': 'http://...</td>\n",
       "      <td>[{'term': 'cond-mat.str-el', 'scheme': 'http:/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Electron Temperature Anisotropy and Electron B...</td>\n",
       "      <td>Electron temperature anisotropies and electron...</td>\n",
       "      <td>[{'name': 'Heyu Sun'}, {'name': 'Jinsong Zhao'...</td>\n",
       "      <td>{'term': 'physics.space-ph', 'scheme': 'http:/...</td>\n",
       "      <td>[{'term': 'physics.space-ph', 'scheme': 'http:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hamiltonian of a many-electron system with sin...</td>\n",
       "      <td>Based on the metastable electron-pair energy b...</td>\n",
       "      <td>[{'name': 'G. -Q. Hai'}, {'name': 'F. M. Peete...</td>\n",
       "      <td>{'term': 'cond-mat.supr-con', 'scheme': 'http:...</td>\n",
       "      <td>[{'term': 'cond-mat.supr-con', 'scheme': 'http...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1170</th>\n",
       "      <td>Level-resolved quantum statistical theory of e...</td>\n",
       "      <td>The strong mixing of many-electron basis state...</td>\n",
       "      <td>[{'name': 'J. C. Berengut'}, {'name': 'C. Hara...</td>\n",
       "      <td>{'term': 'physics.atom-ph', 'scheme': 'http://...</td>\n",
       "      <td>[{'term': 'physics.atom-ph', 'scheme': 'http:/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1171</th>\n",
       "      <td>Nonlinear aspects of quantum plasma physics</td>\n",
       "      <td>Dense quantum plasmas are ubiquitous in planet...</td>\n",
       "      <td>[{'name': 'Padma K. Shukla'}, {'name': 'Bengt ...</td>\n",
       "      <td>{'term': 'physics.plasm-ph', 'scheme': 'http:/...</td>\n",
       "      <td>[{'term': 'physics.plasm-ph', 'scheme': 'http:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1172</th>\n",
       "      <td>Collisional relaxation of electrons in a warm ...</td>\n",
       "      <td>Extending previous studies of nonthermal elect...</td>\n",
       "      <td>[{'name': 'E. P. Kontar'}, {'name': 'N. L. S. ...</td>\n",
       "      <td>{'term': 'astro-ph.SR', 'scheme': 'http://arxi...</td>\n",
       "      <td>[{'term': 'astro-ph.SR', 'scheme': 'http://arx...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1173</th>\n",
       "      <td>Ferromagnetic order of nuclear spins coupled t...</td>\n",
       "      <td>We analyze the ordered state of nuclear spins ...</td>\n",
       "      <td>[{'name': 'Robert Andrzej Zak'}, {'name': 'Dmi...</td>\n",
       "      <td>{'term': 'cond-mat.mes-hall', 'scheme': 'http:...</td>\n",
       "      <td>[{'term': 'cond-mat.mes-hall', 'scheme': 'http...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1174</th>\n",
       "      <td>A quantum reactive scattering perspective on e...</td>\n",
       "      <td>Based on quantum reactive-scattering theory, w...</td>\n",
       "      <td>[{'name': 'Yang Peng'}, {'name': 'Luca M. Ghir...</td>\n",
       "      <td>{'term': 'physics.chem-ph', 'scheme': 'http://...</td>\n",
       "      <td>[{'term': 'physics.chem-ph', 'scheme': 'http:/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1175 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  ...                                               tags\n",
       "0     Impact of Electron-Electron Cusp on Configurat...  ...  [{'term': 'cond-mat.str-el', 'scheme': 'http:/...\n",
       "1     Electron thermal conductivity owing to collisi...  ...  [{'term': 'astro-ph', 'scheme': 'http://arxiv....\n",
       "2     Electron pairing: from metastable electron pai...  ...  [{'term': 'cond-mat.str-el', 'scheme': 'http:/...\n",
       "3     Electron Temperature Anisotropy and Electron B...  ...  [{'term': 'physics.space-ph', 'scheme': 'http:...\n",
       "4     Hamiltonian of a many-electron system with sin...  ...  [{'term': 'cond-mat.supr-con', 'scheme': 'http...\n",
       "...                                                 ...  ...                                                ...\n",
       "1170  Level-resolved quantum statistical theory of e...  ...  [{'term': 'physics.atom-ph', 'scheme': 'http:/...\n",
       "1171        Nonlinear aspects of quantum plasma physics  ...  [{'term': 'physics.plasm-ph', 'scheme': 'http:...\n",
       "1172  Collisional relaxation of electrons in a warm ...  ...  [{'term': 'astro-ph.SR', 'scheme': 'http://arx...\n",
       "1173  Ferromagnetic order of nuclear spins coupled t...  ...  [{'term': 'cond-mat.mes-hall', 'scheme': 'http...\n",
       "1174  A quantum reactive scattering perspective on e...  ...  [{'term': 'physics.chem-ph', 'scheme': 'http:/...\n",
       "\n",
       "[1175 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "liF3C_P68jTs"
   },
   "source": [
    "### tokenizing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fL1_OauX_O5y",
    "outputId": "690514af-0d9f-40f0-f241-16fc12620312"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en_core_web_lg==2.2.5\n",
      "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.2.5/en_core_web_lg-2.2.5.tar.gz (827.9MB)\n",
      "\u001b[K     |████████████████████████████████| 827.9MB 1.1MB/s \n",
      "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_lg==2.2.5) (2.2.4)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.5)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (0.8.2)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (57.0.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (2.23.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (4.41.1)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (0.4.1)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.1.3)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.5)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.19.5)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (3.0.5)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (2.0.5)\n",
      "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (7.4.0)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (2021.5.30)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (2.10)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (4.6.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.4.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.7.4.3)\n",
      "Building wheels for collected packages: en-core-web-lg\n",
      "  Building wheel for en-core-web-lg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for en-core-web-lg: filename=en_core_web_lg-2.2.5-cp37-none-any.whl size=829180945 sha256=0c5fd3e2294ec04b6fa6dd491ebfc80fe001493d962949be1f237035fb5a6494\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-jwc5q3lk/wheels/2a/c1/a6/fc7a877b1efca9bc6a089d6f506f16d3868408f9ff89f8dbfc\n",
      "Successfully built en-core-web-lg\n",
      "Installing collected packages: en-core-web-lg\n",
      "Successfully installed en-core-web-lg-2.2.5\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_lg')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_lg\n",
    "import spacy\n",
    "import en_core_web_lg\n",
    "nlp = en_core_web_lg.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "TrBRUil1zsps"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#taking just the titles (data_list[0]). (maybe to use the summary instaed?)\n",
    "# using lower case. removing extra spaces and '\\n ' \n",
    "doc=[nlp.tokenizer(text.lower().replace('\\n ','').strip()) for text in data_list[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "INkanj23b4oz"
   },
   "source": [
    "for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QeOuK7w6XZa0",
    "outputId": "d8e2f204-a1b3-4e9d-9a4b-dfce65d41a25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15686, 33, 15686, 358821, 29900, 7, 3, 23757, 8, 15686, 18254, 62174, 13, 4085, 17115]\n",
      "[15686, 33, 15686, 358821, 29900, 7, 3, 23757, 8, 15686, 18254, 62174, 13, 4085, 17115]\n",
      "['electron', '-', 'electron', 'bremsstrahlung', 'emission', 'and', 'the', 'inference', 'of', 'electron', 'flux', 'spectra', 'in', 'solar', 'flares']\n",
      "[14911849430818137050, 9153284864653046197, 14911849430818137050, 5074391312506727947, 7093072741639743635, 2283656566040971221, 7425985699627899538, 10770840912364104747, 886050111519832510, 14911849430818137050, 7386502683099369518, 721847661104588153, 3002984154512732771, 3825196732376443040, 54522159426843760]\n"
     ]
    }
   ],
   "source": [
    "II=5;\n",
    "print([token.rank for token in doc[II]])\n",
    "print([token.lex_id for token in doc[II]])\n",
    "print([token.text for token in doc[II]])\n",
    "print([nlp.vocab.strings[token.text] for token in doc[II]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BmDuJLXd4bdd",
    "outputId": "fa36fe2d-1e8b-45ed-db89-0a73632b88c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token 2 corresponds to token: electron\n",
      "Token \"the\" corresponds to index: 31\n"
     ]
    }
   ],
   "source": [
    "# Words_vec= words in the text \n",
    "# Vocab = unique words in the text\n",
    "\n",
    "#import numpy as np\n",
    "\n",
    "#Words=[]\n",
    "#Words_id=[]\n",
    "#Max_Length=30;\n",
    "#Words_vec= np.empty([max_results,Max_Length],dtype='int')\n",
    "\n",
    "\n",
    "#for i in range(99):\n",
    "#  #len([token.lex_id for token in doc[i]])\n",
    "#  Words_vec[i,:len([token.lex_id for token in doc[i]])]=[token.lex_id for token in doc[i]]\n",
    "#  for token in doc[i]:\n",
    "#    #print(token.text, token.has_vector, token.vector, token.vector_norm ,\"\\n\")\n",
    "#    #print(token.text, token.has_vector, token.lex_id ,\"\\n\")\n",
    "#    Words.append(token.text.lower())\n",
    "#    Words_id.append(token.lex_id)\n",
    "\n",
    "    \n",
    "\n",
    "#Vocab = []\n",
    "#Vocab_id = []\n",
    "#[Vocab.append(x) for x in Words if x not in Vocab]\n",
    "#[Vocab_id.append(id) for id in Words_id if id not in Vocab_id]\n",
    "\n",
    "#print('number of unique words in our data=',len(Vocab))\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "class Vocabulary:\n",
    "    PAD_token = 0   # Used for padding short sentences\n",
    "    SOS_token = 1   # Start-of-sentence token\n",
    "    EOS_token = 2   # End-of-sentence token\n",
    "\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {}#{PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\"}\n",
    "        self.num_words = 0\n",
    "        self.num_sentences = 0\n",
    "        self.longest_sentence = 0\n",
    "\n",
    "    def add_word(self, word):\n",
    "        if word not in self.word2index:\n",
    "            # First entry of word into vocabulary\n",
    "            self.word2index[word] = self.num_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.num_words] = word\n",
    "            self.num_words += 1\n",
    "        else:\n",
    "            # Word exists; increase word count\n",
    "            self.word2count[word] += 1\n",
    "            \n",
    "    def add_sentence(self, sentence):\n",
    "        sentence_len = 0\n",
    "        for word in [token.text for token in sentence]:\n",
    "            sentence_len += 1\n",
    "            self.add_word(word)\n",
    "        if sentence_len > self.longest_sentence:\n",
    "            # This is the longest sentence\n",
    "            self.longest_sentence = sentence_len\n",
    "        # Count the number of sentences\n",
    "        self.num_sentences += 1\n",
    "\n",
    "    def to_word(self, index):\n",
    "        return self.index2word[index]\n",
    "\n",
    "    def to_index(self, word):\n",
    "        return self.word2index[word]\n",
    "\n",
    "voc=Vocabulary('test')\n",
    "for sent in doc:\n",
    "  voc.add_sentence(sent)\n",
    "\n",
    "print('Token 2 corresponds to token:', voc.to_word(2))\n",
    "print('Token \"the\" corresponds to index:', voc.to_index('the'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "rhcciczvd5QA"
   },
   "outputs": [],
   "source": [
    "Input_list=[]\n",
    "for sample in range(len(doc)):\n",
    "#  Input_list.append([token.rank for token in doc[sample]])\n",
    "   Input_list.append([voc.to_index(token.text) for token in doc[sample]])\n",
    "Output_list=Input_list;\n",
    "Input_Output_Data_list=[Input_list,Output_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uuanLbDSMRLp",
    "outputId": "f67c82ec-ecab-4ae5-a23d-2f6aec31a126"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[51, 52, 1, 53] improved scenario of baryogenesis\n"
     ]
    }
   ],
   "source": [
    "print(Input_list[6],doc[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "crgSghzkWfaM"
   },
   "outputs": [],
   "source": [
    "## next: to understand / complete\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#10% test set\n",
    "In_train, In_test, Out_train, Out_test = train_test_split(Input_list, Output_list, test_size=0.1, random_state=1)\n",
    "\n",
    "#from 90% train set --> 20% validation and 80 % training (= in total we have 10% test, 18% val, 72% train )\n",
    "In_train, In_val, Out_train, Out_val = train_test_split(In_train, Out_train , test_size=0.2, random_state=1)\n",
    "\n",
    "train_list=  In_train\n",
    "label=Out_train\n",
    "validation_list=In_val\n",
    "test_list=In_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PkIqD548dHjO",
    "outputId": "46435f9d-c2ea-4d00-df2e-97edd5b7d86d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[2249,   31,  401,    2,  452,  331,  338,    2,    2,    2,  955,  885,\n",
       "           741,  526,    2, 2244,  922,  331,  119, 1196,    2,   84,    2,  221,\n",
       "          1716,   35,  433,    2,   71,  553],\n",
       "         [ 222,  331,  919,    3,    3,    1,  435,   71,   21,    3,  103,    1,\n",
       "           742,    3,    3,   25,    1,    1,    2,   16,  219,  596,    3,    3,\n",
       "             1,  247,  331,    3,  243,   31],\n",
       "         [ 499,    1,   30,  123, 1951,  595,   88,    3, 1008,    2,   30,   71,\n",
       "           430,  630,  123, 1929,   35,   31,   97,    5,    3,   96,    2, 1609,\n",
       "            31,    3,   30,   96,    1,  820],\n",
       "         [2250,    2, 2224,   25,   64,    5,    1,  178,   30,  137,  240,   74,\n",
       "             1, 1021,    7, 1256,  240,   74,   30, 1197,  284,   17,   61,   77,\n",
       "            74, 1618,   35,  746,   16,  885],\n",
       "         [  46,  321,   25,    2,  187,   71,    2,   94,  131,   25,  501,  664,\n",
       "             2,    1,   83,   25,    2,    7,  501,  475,  285,   30,   30,    3,\n",
       "          1768,  401,  439,   30,   25,    1],\n",
       "         [  30,    5, 2225,    3,  165,  143,  478,    1, 1009,   10,   64,   30,\n",
       "             3,    2,  716,  269,    3,    5,   64,    0,    2,   31,  244,    2,\n",
       "           174,    2,   38, 1067,  321,  105],\n",
       "         [   2,  276,   41,   84,   35,   30,  211,  403,  199,    1,  956,   35,\n",
       "            84,  567,    3,   84,   84,   31,  505,    0,  286,  940,  424,  499,\n",
       "            12, 1106,  295, 1068,   30,  916],\n",
       "         [ 257, 1709,    3,  656,   71,   35, 2014, 1485,    0,  640,  261,   41,\n",
       "           596,   30,  196, 1811,   97,    2,  506,    0,  104,  112,    0,   40,\n",
       "             2,    0,  408,   18,   35,   30],\n",
       "         [ 502,   46,   42,   30,    3,   41,  150, 1448,    0, 1660,    2,    3,\n",
       "            81,  570,  332,   30,   30,   94,   18,    0,    2,  199,    0, 1761,\n",
       "             3,    0,   16,  922,  439,    2],\n",
       "         [  13,  437,    2,   31, 1300,    3,  284,  317,    0, 1661,  248,   42,\n",
       "            71,    0,  717, 2245, 1881,    1,  327,    0,  287,  431,    0,  211,\n",
       "          1718,    0,   18,   95,   25,  111],\n",
       "         [   0,  211, 1299,  657,    0,   42, 2015,   30,    0,    0,  175,    2,\n",
       "            94,    0,   30,  367,  390,   68,  328,    0,   25, 1387,    0,  524,\n",
       "            13,    0, 1438,   71,   30,  917],\n",
       "         [   0, 1710,    0,    3,    0,    2,    1, 1486,    0,    0,    0,  141,\n",
       "             1,    0,  718,  157,    0,    3,  507,    0,    2,    3,    0,    3,\n",
       "             0,    0,  351,  357,   35,  172],\n",
       "         [   0,  279,    0,  658,    0,  141, 1778,    0,    0,    0,    0,    0,\n",
       "            82,    0,  719,  389,    0,  425,   25,    0,  288, 1388,    0,   42,\n",
       "             0,    0,    0,    1,  138,  382],\n",
       "         [   0,    0,    0,  659,    0,    0, 1779,    0,    0,    0,    0,    0,\n",
       "             3,    0,  720,   16,    0,   64,  210,    0,  289,    0,    0,  401,\n",
       "             0,    0,    0,    2,    0,    0],\n",
       "         [   0,    0,    0,   49,    0,    0,  783,    0,    0,    0,    0,    0,\n",
       "           100,    0,  390,   18,    0,  187,  508,    0,   18,    0,    0,  283,\n",
       "             0,    0,    0,  243,    0,    0],\n",
       "         [   0,    0,    0,    1,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            89,    0,  493, 2184,    0,  239,    0,    0,  290,    0,    0, 1129,\n",
       "             0,    0,    0,   30,    0,    0],\n",
       "         [   0,    0,    0,  660,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            16,    0,    0, 2185,    0,    0,    0,    0,  291,    0,    0,    0,\n",
       "             0,    0,    0,   35,    0,    0],\n",
       "         [   0,    0,    0,    3,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            30,    0,    0, 1410,    0,    0,    0,    0,   95,    0,    0,    0,\n",
       "             0,    0,    0,  295,    0,    0],\n",
       "         [   0,    0,    0,  403,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           153,    0,    0,    0,    0,    0,    0,    0,  292,    0,    0,    0,\n",
       "             0,    0,    0,    2,    0,    0],\n",
       "         [   0,    0,    0,  661,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             3,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,   37,    0,    0],\n",
       "         [   0,    0,    0,  662,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           439,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0],\n",
       "         [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          1170,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0]]),\n",
       " tensor([[2249,   31,  401,    2,  452,  331,  338,    2,    2,    2,  955,  885,\n",
       "           741,  526,    2, 2244,  922,  331,  119, 1196,    2,   84,    2,  221,\n",
       "          1716,   35,  433,    2,   71,  553],\n",
       "         [ 222,  331,  919,    3,    3,    1,  435,   71,   21,    3,  103,    1,\n",
       "           742,    3,    3,   25,    1,    1,    2,   16,  219,  596,    3,    3,\n",
       "             1,  247,  331,    3,  243,   31],\n",
       "         [ 499,    1,   30,  123, 1951,  595,   88,    3, 1008,    2,   30,   71,\n",
       "           430,  630,  123, 1929,   35,   31,   97,    5,    3,   96,    2, 1609,\n",
       "            31,    3,   30,   96,    1,  820],\n",
       "         [2250,    2, 2224,   25,   64,    5,    1,  178,   30,  137,  240,   74,\n",
       "             1, 1021,    7, 1256,  240,   74,   30, 1197,  284,   17,   61,   77,\n",
       "            74, 1618,   35,  746,   16,  885],\n",
       "         [  46,  321,   25,    2,  187,   71,    2,   94,  131,   25,  501,  664,\n",
       "             2,    1,   83,   25,    2,    7,  501,  475,  285,   30,   30,    3,\n",
       "          1768,  401,  439,   30,   25,    1],\n",
       "         [  30,    5, 2225,    3,  165,  143,  478,    1, 1009,   10,   64,   30,\n",
       "             3,    2,  716,  269,    3,    5,   64,    0,    2,   31,  244,    2,\n",
       "           174,    2,   38, 1067,  321,  105],\n",
       "         [   2,  276,   41,   84,   35,   30,  211,  403,  199,    1,  956,   35,\n",
       "            84,  567,    3,   84,   84,   31,  505,    0,  286,  940,  424,  499,\n",
       "            12, 1106,  295, 1068,   30,  916],\n",
       "         [ 257, 1709,    3,  656,   71,   35, 2014, 1485,    0,  640,  261,   41,\n",
       "           596,   30,  196, 1811,   97,    2,  506,    0,  104,  112,    0,   40,\n",
       "             2,    0,  408,   18,   35,   30],\n",
       "         [ 502,   46,   42,   30,    3,   41,  150, 1448,    0, 1660,    2,    3,\n",
       "            81,  570,  332,   30,   30,   94,   18,    0,    2,  199,    0, 1761,\n",
       "             3,    0,   16,  922,  439,    2],\n",
       "         [  13,  437,    2,   31, 1300,    3,  284,  317,    0, 1661,  248,   42,\n",
       "            71,    0,  717, 2245, 1881,    1,  327,    0,  287,  431,    0,  211,\n",
       "          1718,    0,   18,   95,   25,  111],\n",
       "         [   0,  211, 1299,  657,    0,   42, 2015,   30,    0,    0,  175,    2,\n",
       "            94,    0,   30,  367,  390,   68,  328,    0,   25, 1387,    0,  524,\n",
       "            13,    0, 1438,   71,   30,  917],\n",
       "         [   0, 1710,    0,    3,    0,    2,    1, 1486,    0,    0,    0,  141,\n",
       "             1,    0,  718,  157,    0,    3,  507,    0,    2,    3,    0,    3,\n",
       "             0,    0,  351,  357,   35,  172],\n",
       "         [   0,  279,    0,  658,    0,  141, 1778,    0,    0,    0,    0,    0,\n",
       "            82,    0,  719,  389,    0,  425,   25,    0,  288, 1388,    0,   42,\n",
       "             0,    0,    0,    1,  138,  382],\n",
       "         [   0,    0,    0,  659,    0,    0, 1779,    0,    0,    0,    0,    0,\n",
       "             3,    0,  720,   16,    0,   64,  210,    0,  289,    0,    0,  401,\n",
       "             0,    0,    0,    2,    0,    0],\n",
       "         [   0,    0,    0,   49,    0,    0,  783,    0,    0,    0,    0,    0,\n",
       "           100,    0,  390,   18,    0,  187,  508,    0,   18,    0,    0,  283,\n",
       "             0,    0,    0,  243,    0,    0],\n",
       "         [   0,    0,    0,    1,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            89,    0,  493, 2184,    0,  239,    0,    0,  290,    0,    0, 1129,\n",
       "             0,    0,    0,   30,    0,    0],\n",
       "         [   0,    0,    0,  660,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            16,    0,    0, 2185,    0,    0,    0,    0,  291,    0,    0,    0,\n",
       "             0,    0,    0,   35,    0,    0],\n",
       "         [   0,    0,    0,    3,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            30,    0,    0, 1410,    0,    0,    0,    0,   95,    0,    0,    0,\n",
       "             0,    0,    0,  295,    0,    0],\n",
       "         [   0,    0,    0,  403,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           153,    0,    0,    0,    0,    0,    0,    0,  292,    0,    0,    0,\n",
       "             0,    0,    0,    2,    0,    0],\n",
       "         [   0,    0,    0,  661,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             3,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,   37,    0,    0],\n",
       "         [   0,    0,    0,  662,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           439,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0],\n",
       "         [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          1170,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0]]))"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def collate_batch(batch):\n",
    "    label_list, text_list = [], []\n",
    "    for _sample in batch:\n",
    "        label_list.append(torch.tensor(_sample))\n",
    "        text_list.append(torch.tensor(_sample))\n",
    "    return pad_sequence(label_list, padding_value=0.0), pad_sequence(text_list, padding_value=0.0)\n",
    "\n",
    "batch_size = 30\n",
    "\n",
    "def create_iterators(batch_size=batch_size):\n",
    "    \"\"\"Heler function to create the iterators\"\"\"\n",
    "    dataloaders = []\n",
    "    for split in [train_list, validation_list, test_list]:\n",
    "        dataloader = DataLoader(\n",
    "            split, batch_size=batch_size,\n",
    "            collate_fn=collate_batch\n",
    "            )\n",
    "        dataloaders.append(dataloader)\n",
    "    return dataloaders\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = create_iterators()\n",
    "\n",
    "next(iter(train_iterator))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BKin5JYy7J5m",
    "outputId": "4b5e872b-4f62-43da-8cfd-2bf6c6c934fe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 741,   31,    2,   64,    2,  467,  898,    2, 1327,   52, 1693,   55,\n",
       "           320,   64,  468,  866,  393,  957, 1221,  243,   85, 2068,   35,    2,\n",
       "           667,  773,  820,   82,   71,  426],\n",
       "         [ 742, 1053,   84,  105,  243,    1,    3,    3,  243,    1,  188,    3,\n",
       "           321,  103,  630,  747,   71,   16,    2,   78,    2, 2069,   64,    3,\n",
       "          1887,  205, 1452,    3,  143, 1135],\n",
       "         [ 152,    1,  747,  234,   78, 1289,    2,   84,    1,   53, 1694,  347,\n",
       "           322,    1,    3,   19,  482,   18,  141,    1,   61,    3, 1062,    2,\n",
       "             1,  774,  871,   83,    1,    1],\n",
       "         [   1,   59,   30,  125,   30,  612,  545,    7,  846,    0,  199,    1,\n",
       "           323,    2,  658,  105,  283,   10,   19,   35,   30,  657,  137,    7,\n",
       "            31,    2,    1, 1159,   16,   41],\n",
       "         [ 579,  130, 1970,   31,  221, 1382,  899,  392,   16,    0,   18,   41,\n",
       "           324,    3,  557,  867,  153,   25,   41, 1189,  439,  137, 1292,  607,\n",
       "           513,  545,   89,  501,   30,  483],\n",
       "         [   2, 1054,    0,  825,    3,   30,  443,  868,   30,    0,   70,    3,\n",
       "            16,  584,    2,    1,   30,  747,    3, 1984,  493,    1,    5,   12,\n",
       "            41,   30,    3,  502,   64,   16],\n",
       "         [   3,    5,    0,    1, 1609,  119,  900,   83,   31,    0,    1,   42,\n",
       "           261,  240,  837,  868,  131,    0,  338,   30,    0, 1205,  105,   10,\n",
       "             3,  775,    2,  125,  144,    5],\n",
       "         [  84, 1055,    0,  888, 1599,  239,  901,   81,   32,    0, 1386,  826,\n",
       "           325,   37,    0,  869,  483,    0,  386,  131,    0,   16, 1341,   30,\n",
       "             2,  776,   94,   25,    0, 1136],\n",
       "         [  73,  137,    0, 1748,  710,    0,   19,  535, 1328,    0,   25,    2,\n",
       "           261,   30,    0,  241,  249,    0,    0,  207,    0,    0,    0,  608,\n",
       "           724,    3,   30, 1071,    0,  644],\n",
       "         [1073,   30,    0,   25,   12,    0,   31,  103,   18,    0,    7,  239,\n",
       "            31,   64,    0,    0,    2,    0,    0,    3,    0,    0,    0,  609,\n",
       "             0,  502,   35,   31,    0,    3],\n",
       "         [  30,  452,    0, 1197, 1610,    0,   54,    1,  529,    0,   30,   30,\n",
       "           200,  402,    0,    0,  141,    0,    0,  208,    0,    0,    0,    0,\n",
       "             0,    0,   84, 1160,    0,   54],\n",
       "         [1074,    3,    0,  475,  315,    0,  902,  606,    3,    0,  249,   31,\n",
       "             1,    0,    0,    0,    0,    0,    0,  759,    0,    0,    0,    0,\n",
       "             0,    0,    3,    3,    0,  538],\n",
       "         [   0, 1056,    0,    0,    0,    0,  903,  335,  530,    0,    2,   64,\n",
       "            31,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0, 1453,  305,    0,    0],\n",
       "         [   0,   41,    0,    0,    0,    0,    0, 2126,   25,    0,  239,  597,\n",
       "             2,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,  439,    3,    0,    0],\n",
       "         [   0,    3,    0,    0,    0,    0,    0,  424, 1329,    0,    0,  297,\n",
       "             3,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,  909,  205,    0,    0],\n",
       "         [   0, 1057,    0,    0,    0,    0,    0,    0, 1330,    0,    0,    0,\n",
       "           150,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0, 1161,    0,    0],\n",
       "         [   0,  299,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             7,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0]]),\n",
       " tensor([[ 741,   31,    2,   64,    2,  467,  898,    2, 1327,   52, 1693,   55,\n",
       "           320,   64,  468,  866,  393,  957, 1221,  243,   85, 2068,   35,    2,\n",
       "           667,  773,  820,   82,   71,  426],\n",
       "         [ 742, 1053,   84,  105,  243,    1,    3,    3,  243,    1,  188,    3,\n",
       "           321,  103,  630,  747,   71,   16,    2,   78,    2, 2069,   64,    3,\n",
       "          1887,  205, 1452,    3,  143, 1135],\n",
       "         [ 152,    1,  747,  234,   78, 1289,    2,   84,    1,   53, 1694,  347,\n",
       "           322,    1,    3,   19,  482,   18,  141,    1,   61,    3, 1062,    2,\n",
       "             1,  774,  871,   83,    1,    1],\n",
       "         [   1,   59,   30,  125,   30,  612,  545,    7,  846,    0,  199,    1,\n",
       "           323,    2,  658,  105,  283,   10,   19,   35,   30,  657,  137,    7,\n",
       "            31,    2,    1, 1159,   16,   41],\n",
       "         [ 579,  130, 1970,   31,  221, 1382,  899,  392,   16,    0,   18,   41,\n",
       "           324,    3,  557,  867,  153,   25,   41, 1189,  439,  137, 1292,  607,\n",
       "           513,  545,   89,  501,   30,  483],\n",
       "         [   2, 1054,    0,  825,    3,   30,  443,  868,   30,    0,   70,    3,\n",
       "            16,  584,    2,    1,   30,  747,    3, 1984,  493,    1,    5,   12,\n",
       "            41,   30,    3,  502,   64,   16],\n",
       "         [   3,    5,    0,    1, 1609,  119,  900,   83,   31,    0,    1,   42,\n",
       "           261,  240,  837,  868,  131,    0,  338,   30,    0, 1205,  105,   10,\n",
       "             3,  775,    2,  125,  144,    5],\n",
       "         [  84, 1055,    0,  888, 1599,  239,  901,   81,   32,    0, 1386,  826,\n",
       "           325,   37,    0,  869,  483,    0,  386,  131,    0,   16, 1341,   30,\n",
       "             2,  776,   94,   25,    0, 1136],\n",
       "         [  73,  137,    0, 1748,  710,    0,   19,  535, 1328,    0,   25,    2,\n",
       "           261,   30,    0,  241,  249,    0,    0,  207,    0,    0,    0,  608,\n",
       "           724,    3,   30, 1071,    0,  644],\n",
       "         [1073,   30,    0,   25,   12,    0,   31,  103,   18,    0,    7,  239,\n",
       "            31,   64,    0,    0,    2,    0,    0,    3,    0,    0,    0,  609,\n",
       "             0,  502,   35,   31,    0,    3],\n",
       "         [  30,  452,    0, 1197, 1610,    0,   54,    1,  529,    0,   30,   30,\n",
       "           200,  402,    0,    0,  141,    0,    0,  208,    0,    0,    0,    0,\n",
       "             0,    0,   84, 1160,    0,   54],\n",
       "         [1074,    3,    0,  475,  315,    0,  902,  606,    3,    0,  249,   31,\n",
       "             1,    0,    0,    0,    0,    0,    0,  759,    0,    0,    0,    0,\n",
       "             0,    0,    3,    3,    0,  538],\n",
       "         [   0, 1056,    0,    0,    0,    0,  903,  335,  530,    0,    2,   64,\n",
       "            31,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0, 1453,  305,    0,    0],\n",
       "         [   0,   41,    0,    0,    0,    0,    0, 2126,   25,    0,  239,  597,\n",
       "             2,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,  439,    3,    0,    0],\n",
       "         [   0,    3,    0,    0,    0,    0,    0,  424, 1329,    0,    0,  297,\n",
       "             3,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,  909,  205,    0,    0],\n",
       "         [   0, 1057,    0,    0,    0,    0,    0,    0, 1330,    0,    0,    0,\n",
       "           150,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0, 1161,    0,    0],\n",
       "         [   0,  299,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             7,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0]]))"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(valid_iterator))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oBhvp2gOw9nN",
    "outputId": "cee0a1fc-8879-49ec-f4f6-993806bfeb89"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[51, 52, 1, 53] improved scenario of baryogenesis\n"
     ]
    }
   ],
   "source": [
    "print(Input_list[6],doc[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "5AolSQ__6D5Y"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "\n",
    "    def __init__(self, ntoken, ninp, nhead, nhid, nlayers, dropout=0.5):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.model_type = 'Transformer'\n",
    "        self.pos_encoder = PositionalEncoding(ninp, dropout)\n",
    "        encoder_layers = TransformerEncoderLayer(ninp, nhead, nhid, dropout)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
    "        self.encoder = nn.Embedding(ntoken, ninp)\n",
    "        self.ninp = ninp\n",
    "        self.decoder = nn.Linear(ninp, ntoken)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def generate_square_subsequent_mask(self, sz):\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        return mask\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
    "        self.decoder.bias.data.zero_()\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, src, src_mask):\n",
    "        src = self.encoder(src) * math.sqrt(self.ninp)\n",
    "        src = self.pos_encoder(src)\n",
    "        output = self.transformer_encoder(src, src_mask)\n",
    "        output = self.decoder(output)\n",
    "        return output\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "IokyuWyL6E_b"
   },
   "outputs": [],
   "source": [
    "ntokens = (voc.num_words)#max(Vocab_id) # the size of vocabulary\n",
    "device='cpu'\n",
    "emsize = 200 # embedding dimension\n",
    "nhid = 200 # the dimension of the feedforward network model in nn.TransformerEncoder\n",
    "nlayers = 2 # the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
    "nhead = 2 # the number of heads in the multiheadattention models\n",
    "dropout = 0.2 # the dropout value\n",
    "bptt=35\n",
    "model = TransformerModel(ntokens, emsize, nhead, nhid, nlayers, dropout).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "x_KSFqEm6ZJD"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "lr = 5.0 # learning rate\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)\n",
    "\n",
    "train_data=In_train\n",
    "\n",
    "def train():\n",
    "    model.train() # Turn on the train mode\n",
    "    total_loss = 0.\n",
    "    start_time = time.time()\n",
    "    src_mask = model.generate_square_subsequent_mask(bptt).to(device)\n",
    "    for batch, i in enumerate(range(0, len(train_data) - 1, bptt)):\n",
    "        train_iterator, valid_iterator, test_iterator = create_iterators()\n",
    "        data, targets=next(iter(train_iterator))\n",
    "        optimizer.zero_grad()\n",
    "        if data.size(0) != bptt:\n",
    "            src_mask = model.generate_square_subsequent_mask(data.size(0)).to(device)\n",
    "        output = model(data, src_mask)\n",
    "        loss = criterion(output.view(-1, ntokens), targets.view(-1))\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        log_interval = 200\n",
    "        if batch % log_interval == 0 and batch > 0:\n",
    "            cur_loss = total_loss / log_interval\n",
    "            elapsed = time.time() - start_time\n",
    "            print('| epoch {:3d} | {:5d}/{:5d} batches | '\n",
    "                  'lr {:02.2f} | ms/batch {:5.2f} | '\n",
    "                  'loss {:5.2f} | ppl {:8.2f}'.format(\n",
    "                    epoch, batch, len(train_data) // bptt, scheduler.get_last_lr()[0],\n",
    "                    elapsed * 1000 / log_interval,\n",
    "                    cur_loss, math.exp(cur_loss)))\n",
    "            total_loss = 0\n",
    "            start_time = time.time()\n",
    "\n",
    "def evaluate(eval_model, data_source):\n",
    "    eval_model.eval() # Turn on the evaluation mode\n",
    "    total_loss = 0.\n",
    "    src_mask = model.generate_square_subsequent_mask(bptt).to(device)\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, data_source.size(0) - 1, bptt):\n",
    "            train_iterator, valid_iterator, test_iterator = create_iterators()\n",
    "            data, targets=next(iter(valid_iterator))\n",
    "            if data.size(0) != bptt:\n",
    "                src_mask = model.generate_square_subsequent_mask(data.size(0)).to(device)\n",
    "            output = eval_model(data, src_mask)\n",
    "            output_flat = output.view(-1, ntokens)\n",
    "            total_loss += len(data) * criterion(output_flat, targets.view(-1)).item()\n",
    "    return total_loss / (len(data_source) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2QMNU7Ht6g4k",
    "outputId": "aebe9c49-77f5-4d94-f965-8a1773d2c0be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   1 | time:  2.09s | valid loss  2.50 | valid ppl    12.16\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   2 | time:  2.07s | valid loss  2.53 | valid ppl    12.52\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   3 | time:  2.07s | valid loss  2.54 | valid ppl    12.71\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   4 | time:  2.06s | valid loss  2.55 | valid ppl    12.84\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   5 | time:  2.06s | valid loss  2.56 | valid ppl    12.94\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   6 | time:  2.10s | valid loss  2.57 | valid ppl    13.01\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   7 | time:  2.08s | valid loss  2.57 | valid ppl    13.07\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   8 | time:  2.08s | valid loss  2.57 | valid ppl    13.13\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   9 | time:  2.06s | valid loss  2.58 | valid ppl    13.17\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  10 | time:  2.09s | valid loss  2.58 | valid ppl    13.22\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  11 | time:  2.12s | valid loss  2.58 | valid ppl    13.26\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  12 | time:  2.18s | valid loss  2.59 | valid ppl    13.29\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  13 | time:  2.18s | valid loss  2.59 | valid ppl    13.32\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  14 | time:  2.19s | valid loss  2.59 | valid ppl    13.35\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  15 | time:  2.17s | valid loss  2.59 | valid ppl    13.37\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  16 | time:  2.16s | valid loss  2.59 | valid ppl    13.39\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  17 | time:  2.16s | valid loss  2.60 | valid ppl    13.41\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  18 | time:  2.16s | valid loss  2.60 | valid ppl    13.43\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  19 | time:  2.16s | valid loss  2.60 | valid ppl    13.45\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  20 | time:  2.16s | valid loss  2.60 | valid ppl    13.46\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  21 | time:  2.14s | valid loss  2.60 | valid ppl    13.48\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  22 | time:  2.15s | valid loss  2.60 | valid ppl    13.49\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  23 | time:  2.17s | valid loss  2.60 | valid ppl    13.50\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  24 | time:  2.16s | valid loss  2.60 | valid ppl    13.51\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  25 | time:  2.16s | valid loss  2.60 | valid ppl    13.52\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  26 | time:  2.17s | valid loss  2.61 | valid ppl    13.53\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  27 | time:  2.15s | valid loss  2.61 | valid ppl    13.54\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  28 | time:  2.18s | valid loss  2.61 | valid ppl    13.55\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  29 | time:  2.18s | valid loss  2.61 | valid ppl    13.56\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  30 | time:  2.16s | valid loss  2.61 | valid ppl    13.57\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  31 | time:  2.16s | valid loss  2.61 | valid ppl    13.58\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  32 | time:  2.16s | valid loss  2.61 | valid ppl    13.58\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  33 | time:  2.16s | valid loss  2.61 | valid ppl    13.59\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  34 | time:  2.19s | valid loss  2.61 | valid ppl    13.60\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  35 | time:  2.15s | valid loss  2.61 | valid ppl    13.60\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  36 | time:  2.17s | valid loss  2.61 | valid ppl    13.61\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  37 | time:  2.18s | valid loss  2.61 | valid ppl    13.61\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  38 | time:  2.19s | valid loss  2.61 | valid ppl    13.62\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  39 | time:  2.15s | valid loss  2.61 | valid ppl    13.62\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  40 | time:  2.16s | valid loss  2.61 | valid ppl    13.62\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  41 | time:  2.17s | valid loss  2.61 | valid ppl    13.63\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  42 | time:  2.17s | valid loss  2.61 | valid ppl    13.63\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  43 | time:  2.18s | valid loss  2.61 | valid ppl    13.64\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  44 | time:  2.15s | valid loss  2.61 | valid ppl    13.64\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  45 | time:  2.17s | valid loss  2.61 | valid ppl    13.64\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  46 | time:  2.17s | valid loss  2.61 | valid ppl    13.65\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  47 | time:  2.18s | valid loss  2.61 | valid ppl    13.65\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  48 | time:  2.17s | valid loss  2.61 | valid ppl    13.65\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  49 | time:  2.16s | valid loss  2.61 | valid ppl    13.65\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  50 | time:  2.13s | valid loss  2.61 | valid ppl    13.66\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  51 | time:  2.10s | valid loss  2.61 | valid ppl    13.66\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  52 | time:  2.10s | valid loss  2.61 | valid ppl    13.66\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  53 | time:  2.12s | valid loss  2.61 | valid ppl    13.66\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  54 | time:  2.12s | valid loss  2.61 | valid ppl    13.66\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  55 | time:  2.10s | valid loss  2.61 | valid ppl    13.67\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  56 | time:  2.11s | valid loss  2.62 | valid ppl    13.67\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  57 | time:  2.12s | valid loss  2.62 | valid ppl    13.67\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  58 | time:  2.13s | valid loss  2.62 | valid ppl    13.67\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  59 | time:  2.10s | valid loss  2.62 | valid ppl    13.67\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  60 | time:  2.09s | valid loss  2.62 | valid ppl    13.67\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  61 | time:  2.11s | valid loss  2.62 | valid ppl    13.67\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  62 | time:  2.11s | valid loss  2.62 | valid ppl    13.68\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  63 | time:  2.08s | valid loss  2.62 | valid ppl    13.68\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  64 | time:  2.09s | valid loss  2.62 | valid ppl    13.68\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  65 | time:  2.09s | valid loss  2.62 | valid ppl    13.68\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  66 | time:  2.08s | valid loss  2.62 | valid ppl    13.68\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  67 | time:  2.12s | valid loss  2.62 | valid ppl    13.68\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  68 | time:  2.13s | valid loss  2.62 | valid ppl    13.68\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  69 | time:  2.10s | valid loss  2.62 | valid ppl    13.68\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  70 | time:  2.09s | valid loss  2.62 | valid ppl    13.68\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  71 | time:  2.10s | valid loss  2.62 | valid ppl    13.68\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  72 | time:  2.10s | valid loss  2.62 | valid ppl    13.68\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  73 | time:  2.08s | valid loss  2.62 | valid ppl    13.69\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  74 | time:  2.08s | valid loss  2.62 | valid ppl    13.69\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  75 | time:  2.09s | valid loss  2.62 | valid ppl    13.69\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  76 | time:  2.07s | valid loss  2.62 | valid ppl    13.69\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  77 | time:  2.06s | valid loss  2.62 | valid ppl    13.69\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  78 | time:  2.09s | valid loss  2.62 | valid ppl    13.69\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  79 | time:  2.07s | valid loss  2.62 | valid ppl    13.69\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  80 | time:  2.05s | valid loss  2.62 | valid ppl    13.69\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  81 | time:  2.08s | valid loss  2.62 | valid ppl    13.69\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  82 | time:  2.08s | valid loss  2.62 | valid ppl    13.69\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  83 | time:  2.08s | valid loss  2.62 | valid ppl    13.69\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  84 | time:  2.08s | valid loss  2.62 | valid ppl    13.69\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  85 | time:  2.10s | valid loss  2.62 | valid ppl    13.69\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  86 | time:  2.09s | valid loss  2.62 | valid ppl    13.69\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  87 | time:  2.09s | valid loss  2.62 | valid ppl    13.69\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  88 | time:  2.05s | valid loss  2.62 | valid ppl    13.69\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  89 | time:  2.06s | valid loss  2.62 | valid ppl    13.69\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  90 | time:  2.07s | valid loss  2.62 | valid ppl    13.69\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  91 | time:  2.08s | valid loss  2.62 | valid ppl    13.69\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  92 | time:  2.06s | valid loss  2.62 | valid ppl    13.69\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  93 | time:  2.05s | valid loss  2.62 | valid ppl    13.69\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  94 | time:  2.06s | valid loss  2.62 | valid ppl    13.69\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  95 | time:  2.08s | valid loss  2.62 | valid ppl    13.69\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  96 | time:  2.07s | valid loss  2.62 | valid ppl    13.69\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  97 | time:  2.05s | valid loss  2.62 | valid ppl    13.69\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  98 | time:  2.06s | valid loss  2.62 | valid ppl    13.69\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  99 | time:  2.04s | valid loss  2.62 | valid ppl    13.70\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 100 | time:  2.04s | valid loss  2.62 | valid ppl    13.70\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "best_val_loss = float(\"inf\")\n",
    "epochs = 100 # The number of epochs\n",
    "best_model = None\n",
    "\n",
    "val_data, targets =next(iter(valid_iterator))\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    train()\n",
    "    val_loss = evaluate(model, val_data)\n",
    "    print('-' * 89)\n",
    "    print('| end of epoch {:3d} | time: {:5.2f}s | valid loss {:5.2f} | '\n",
    "          'valid ppl {:8.2f}'.format(epoch, (time.time() - epoch_start_time),\n",
    "                                     val_loss, math.exp(val_loss)))\n",
    "    print('-' * 89)\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model = model\n",
    "\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gugG0YQM9Ejh"
   },
   "source": [
    "##Generating..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tTD4klY0_Lz4",
    "outputId": "94d4682e-320f-4f5a-f79d-aa0a61e03414"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[2249,   31,  401,    2,  452,  331,  338,    2,    2,    2,  955,  885,\n",
       "           741,  526,    2, 2244,  922,  331,  119, 1196,    2,   84,    2,  221,\n",
       "          1716,   35,  433,    2,   71,  553],\n",
       "         [ 222,  331,  919,    3,    3,    1,  435,   71,   21,    3,  103,    1,\n",
       "           742,    3,    3,   25,    1,    1,    2,   16,  219,  596,    3,    3,\n",
       "             1,  247,  331,    3,  243,   31],\n",
       "         [ 499,    1,   30,  123, 1951,  595,   88,    3, 1008,    2,   30,   71,\n",
       "           430,  630,  123, 1929,   35,   31,   97,    5,    3,   96,    2, 1609,\n",
       "            31,    3,   30,   96,    1,  820],\n",
       "         [2250,    2, 2224,   25,   64,    5,    1,  178,   30,  137,  240,   74,\n",
       "             1, 1021,    7, 1256,  240,   74,   30, 1197,  284,   17,   61,   77,\n",
       "            74, 1618,   35,  746,   16,  885],\n",
       "         [  46,  321,   25,    2,  187,   71,    2,   94,  131,   25,  501,  664,\n",
       "             2,    1,   83,   25,    2,    7,  501,  475,  285,   30,   30,    3,\n",
       "          1768,  401,  439,   30,   25,    1],\n",
       "         [  30,    5, 2225,    3,  165,  143,  478,    1, 1009,   10,   64,   30,\n",
       "             3,    2,  716,  269,    3,    5,   64,    0,    2,   31,  244,    2,\n",
       "           174,    2,   38, 1067,  321,  105],\n",
       "         [   2,  276,   41,   84,   35,   30,  211,  403,  199,    1,  956,   35,\n",
       "            84,  567,    3,   84,   84,   31,  505,    0,  286,  940,  424,  499,\n",
       "            12, 1106,  295, 1068,   30,  916],\n",
       "         [ 257, 1709,    3,  656,   71,   35, 2014, 1485,    0,  640,  261,   41,\n",
       "           596,   30,  196, 1811,   97,    2,  506,    0,  104,  112,    0,   40,\n",
       "             2,    0,  408,   18,   35,   30],\n",
       "         [ 502,   46,   42,   30,    3,   41,  150, 1448,    0, 1660,    2,    3,\n",
       "            81,  570,  332,   30,   30,   94,   18,    0,    2,  199,    0, 1761,\n",
       "             3,    0,   16,  922,  439,    2],\n",
       "         [  13,  437,    2,   31, 1300,    3,  284,  317,    0, 1661,  248,   42,\n",
       "            71,    0,  717, 2245, 1881,    1,  327,    0,  287,  431,    0,  211,\n",
       "          1718,    0,   18,   95,   25,  111],\n",
       "         [   0,  211, 1299,  657,    0,   42, 2015,   30,    0,    0,  175,    2,\n",
       "            94,    0,   30,  367,  390,   68,  328,    0,   25, 1387,    0,  524,\n",
       "            13,    0, 1438,   71,   30,  917],\n",
       "         [   0, 1710,    0,    3,    0,    2,    1, 1486,    0,    0,    0,  141,\n",
       "             1,    0,  718,  157,    0,    3,  507,    0,    2,    3,    0,    3,\n",
       "             0,    0,  351,  357,   35,  172],\n",
       "         [   0,  279,    0,  658,    0,  141, 1778,    0,    0,    0,    0,    0,\n",
       "            82,    0,  719,  389,    0,  425,   25,    0,  288, 1388,    0,   42,\n",
       "             0,    0,    0,    1,  138,  382],\n",
       "         [   0,    0,    0,  659,    0,    0, 1779,    0,    0,    0,    0,    0,\n",
       "             3,    0,  720,   16,    0,   64,  210,    0,  289,    0,    0,  401,\n",
       "             0,    0,    0,    2,    0,    0],\n",
       "         [   0,    0,    0,   49,    0,    0,  783,    0,    0,    0,    0,    0,\n",
       "           100,    0,  390,   18,    0,  187,  508,    0,   18,    0,    0,  283,\n",
       "             0,    0,    0,  243,    0,    0],\n",
       "         [   0,    0,    0,    1,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            89,    0,  493, 2184,    0,  239,    0,    0,  290,    0,    0, 1129,\n",
       "             0,    0,    0,   30,    0,    0],\n",
       "         [   0,    0,    0,  660,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            16,    0,    0, 2185,    0,    0,    0,    0,  291,    0,    0,    0,\n",
       "             0,    0,    0,   35,    0,    0],\n",
       "         [   0,    0,    0,    3,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            30,    0,    0, 1410,    0,    0,    0,    0,   95,    0,    0,    0,\n",
       "             0,    0,    0,  295,    0,    0],\n",
       "         [   0,    0,    0,  403,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           153,    0,    0,    0,    0,    0,    0,    0,  292,    0,    0,    0,\n",
       "             0,    0,    0,    2,    0,    0],\n",
       "         [   0,    0,    0,  661,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             3,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,   37,    0,    0],\n",
       "         [   0,    0,    0,  662,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           439,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0],\n",
       "         [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          1170,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0]]),\n",
       " tensor([[2249,   31,  401,    2,  452,  331,  338,    2,    2,    2,  955,  885,\n",
       "           741,  526,    2, 2244,  922,  331,  119, 1196,    2,   84,    2,  221,\n",
       "          1716,   35,  433,    2,   71,  553],\n",
       "         [ 222,  331,  919,    3,    3,    1,  435,   71,   21,    3,  103,    1,\n",
       "           742,    3,    3,   25,    1,    1,    2,   16,  219,  596,    3,    3,\n",
       "             1,  247,  331,    3,  243,   31],\n",
       "         [ 499,    1,   30,  123, 1951,  595,   88,    3, 1008,    2,   30,   71,\n",
       "           430,  630,  123, 1929,   35,   31,   97,    5,    3,   96,    2, 1609,\n",
       "            31,    3,   30,   96,    1,  820],\n",
       "         [2250,    2, 2224,   25,   64,    5,    1,  178,   30,  137,  240,   74,\n",
       "             1, 1021,    7, 1256,  240,   74,   30, 1197,  284,   17,   61,   77,\n",
       "            74, 1618,   35,  746,   16,  885],\n",
       "         [  46,  321,   25,    2,  187,   71,    2,   94,  131,   25,  501,  664,\n",
       "             2,    1,   83,   25,    2,    7,  501,  475,  285,   30,   30,    3,\n",
       "          1768,  401,  439,   30,   25,    1],\n",
       "         [  30,    5, 2225,    3,  165,  143,  478,    1, 1009,   10,   64,   30,\n",
       "             3,    2,  716,  269,    3,    5,   64,    0,    2,   31,  244,    2,\n",
       "           174,    2,   38, 1067,  321,  105],\n",
       "         [   2,  276,   41,   84,   35,   30,  211,  403,  199,    1,  956,   35,\n",
       "            84,  567,    3,   84,   84,   31,  505,    0,  286,  940,  424,  499,\n",
       "            12, 1106,  295, 1068,   30,  916],\n",
       "         [ 257, 1709,    3,  656,   71,   35, 2014, 1485,    0,  640,  261,   41,\n",
       "           596,   30,  196, 1811,   97,    2,  506,    0,  104,  112,    0,   40,\n",
       "             2,    0,  408,   18,   35,   30],\n",
       "         [ 502,   46,   42,   30,    3,   41,  150, 1448,    0, 1660,    2,    3,\n",
       "            81,  570,  332,   30,   30,   94,   18,    0,    2,  199,    0, 1761,\n",
       "             3,    0,   16,  922,  439,    2],\n",
       "         [  13,  437,    2,   31, 1300,    3,  284,  317,    0, 1661,  248,   42,\n",
       "            71,    0,  717, 2245, 1881,    1,  327,    0,  287,  431,    0,  211,\n",
       "          1718,    0,   18,   95,   25,  111],\n",
       "         [   0,  211, 1299,  657,    0,   42, 2015,   30,    0,    0,  175,    2,\n",
       "            94,    0,   30,  367,  390,   68,  328,    0,   25, 1387,    0,  524,\n",
       "            13,    0, 1438,   71,   30,  917],\n",
       "         [   0, 1710,    0,    3,    0,    2,    1, 1486,    0,    0,    0,  141,\n",
       "             1,    0,  718,  157,    0,    3,  507,    0,    2,    3,    0,    3,\n",
       "             0,    0,  351,  357,   35,  172],\n",
       "         [   0,  279,    0,  658,    0,  141, 1778,    0,    0,    0,    0,    0,\n",
       "            82,    0,  719,  389,    0,  425,   25,    0,  288, 1388,    0,   42,\n",
       "             0,    0,    0,    1,  138,  382],\n",
       "         [   0,    0,    0,  659,    0,    0, 1779,    0,    0,    0,    0,    0,\n",
       "             3,    0,  720,   16,    0,   64,  210,    0,  289,    0,    0,  401,\n",
       "             0,    0,    0,    2,    0,    0],\n",
       "         [   0,    0,    0,   49,    0,    0,  783,    0,    0,    0,    0,    0,\n",
       "           100,    0,  390,   18,    0,  187,  508,    0,   18,    0,    0,  283,\n",
       "             0,    0,    0,  243,    0,    0],\n",
       "         [   0,    0,    0,    1,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            89,    0,  493, 2184,    0,  239,    0,    0,  290,    0,    0, 1129,\n",
       "             0,    0,    0,   30,    0,    0],\n",
       "         [   0,    0,    0,  660,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            16,    0,    0, 2185,    0,    0,    0,    0,  291,    0,    0,    0,\n",
       "             0,    0,    0,   35,    0,    0],\n",
       "         [   0,    0,    0,    3,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            30,    0,    0, 1410,    0,    0,    0,    0,   95,    0,    0,    0,\n",
       "             0,    0,    0,  295,    0,    0],\n",
       "         [   0,    0,    0,  403,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           153,    0,    0,    0,    0,    0,    0,    0,  292,    0,    0,    0,\n",
       "             0,    0,    0,    2,    0,    0],\n",
       "         [   0,    0,    0,  661,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             3,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,   37,    0,    0],\n",
       "         [   0,    0,    0,  662,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           439,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0],\n",
       "         [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          1170,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0]]))"
      ]
     },
     "execution_count": 37,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_iterator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P6qo2jIUDi7A",
    "outputId": "8d2368a7-433c-45fe-ca0d-536e409e5931"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['disordered', 'electron', 'interactions', 'in', 'metal', 'films', 'impact', 'impact', 'impact', 'impact', 'impact', 'impact', 'impact', 'impact', 'impact', 'impact', 'impact']\n"
     ]
    }
   ],
   "source": [
    "#test1= torch.as_tensor([4,5,7,1,81])\n",
    "\n",
    "def generate(model, data_source):\n",
    "    model.eval() # Turn on the evaluation mode\n",
    "    total_loss = 0.\n",
    "    src_mask = model.generate_square_subsequent_mask(bptt).to(device)\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, data_source.size(0) - 1, bptt):\n",
    "            train_iterator, valid_iterator, test_iterator = create_iterators()\n",
    "            data, targets=next(iter(valid_iterator))\n",
    "            if data.size(0) != bptt:\n",
    "                src_mask = model.generate_square_subsequent_mask(data.size(0)).to(device)\n",
    "            output = model(data, src_mask)\n",
    "    return output\n",
    "\n",
    "#test11, targets=next(iter(test_iterator))\n",
    "test1=torch.as_tensor(Input_list[2])#.tolist()\n",
    "#print(torch.argmax(generate(model,test1),dim=2))\n",
    "out=torch.argmax(generate(model,test1),dim=2)\n",
    "#print(out.shape,test1.shape)\n",
    "print([voc.to_word(index) for index in out[:,20].tolist()])\n",
    "\n",
    "#src_mask=model.generate_square_subsequent_mask(test1.size(0)).to(device)\n",
    "#print(model.forward(test1,src_mask).shape)\n",
    "#print(torch.argmax(model.forward(test1,src_mask),dim=2))\n",
    "#out=torch.argmax(model.forward(test1,src_mask),dim=2)\n",
    "#print([voc.to_word(index) for index in test1.tolist()])\n",
    "#print([voc.to_word(index) for index in out[4].tolist()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 161
    },
    "id": "isc5r5s-zrYx",
    "outputId": "7d073995-d968-45d4-a264-e15229ef8691"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-973089eaafbc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_word\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'test1' is not defined"
     ]
    }
   ],
   "source": [
    "print([voc.to_word(index) for index in test1.tolist()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zqoVEWy8F5n2"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nAwOhMvHIq6m"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Untitled0.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
